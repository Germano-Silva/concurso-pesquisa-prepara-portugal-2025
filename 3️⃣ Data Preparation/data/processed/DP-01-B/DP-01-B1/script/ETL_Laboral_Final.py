#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
=============================================================================
SCRIPT ETL COMPLETO - DADOS LABORAIS CENSOS 2021 PORTUGAL
=============================================================================

Autor: Sistema ETL Automatizado  
Data: Dezembro 2024
Fonte: INE - Censos 2021

OBJETIVO:
Processar 8 arquivos CSV dos Censos 2021 e criar modelo relacional normalizado
(3FN/BCNF) integrado com o modelo educacional existente (DP-01-A)

ARQUIVOS DE ENTRADA:
- Q3.1.csv: Popula√ß√£o por nacionalidade e condi√ß√£o econ√¥mica
- Q3.2.csv: Popula√ß√£o empregada por nacionalidade e profiss√£o  
- Q3.3.csv: Popula√ß√£o empregada por nacionalidade e setor
- Q3.4.csv: Popula√ß√£o empregada por nacionalidade e situa√ß√£o
- Q20.csv: Popula√ß√£o empregada por profiss√£o e sexo
- Q21.csv: Popula√ß√£o empregada por regi√£o e setor
- Q23.csv: Popula√ß√£o por escolaridade, trabalho e sexo
- Q24.csv: Popula√ß√£o por regi√£o e fonte de rendimento

SA√çDA:
- 7 tabelas dimensionais + 8 tabelas de fato em formato CSV
- √çndice de tabelas geradas
- Relat√≥rio de estat√≠sticas e valida√ß√µes
- Log detalhado do processamento
=============================================================================
"""

import pandas as pd
import numpy as np
import logging
import warnings
import sys
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# ============================================================================
# CONFIGURA√á√ÉO
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('etl_laboral_log.txt', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

warnings.filterwarnings('ignore')

# ============================================================================
# CLASSE PRINCIPAL ETL
# ============================================================================

class ETLLaboralProcessor:
    """Processador ETL para dados laborais dos Censos 2021"""
    
    def __init__(self):
        """Inicializa o processador ETL"""
        self.logger = logging.getLogger(__name__)
        self.raw_data = {}
        self.reference_tables = {}
        self.dimensional_tables = {}
        self.fact_tables = {}
        self.statistics = {
            'files_processed': 0,
            'records_input': 0,
            'records_output': 0,
            'validation_errors': [],
            'warnings': []
        }
        
        # Arquivos de entrada com variantes para Google Colab
        self.input_files = {
            'Q3.1': ['Q3.1.csv', 'Q3.1 (1).csv'],
            'Q3.2': ['Q3.2.csv', 'Q3.2 (1).csv'],
            'Q3.3': ['Q3.3.csv', 'Q3.3 (1).csv'],
            'Q3.4': ['Q3.4.csv', 'Q3.4 (1).csv'],
            'Q20': ['Q20.csv', 'Q20 (1).csv'],
            'Q21': ['Q21.csv', 'Q21 (1).csv'],
            'Q23': ['Q23.csv', 'Q23 (1).csv'],
            'Q24': ['Q24.csv', 'Q24 (1).csv']
        }
        
        self.logger.info("‚úÖ ETL Processor inicializado")

    # ========================================================================
    # UTILIT√ÅRIOS
    # ========================================================================

    def normalize_text(self, text: str) -> str:
        """Normaliza texto removendo caracteres especiais"""
        if pd.isna(text) or not isinstance(text, str):
            return text
            
        replacements = {
            '–≥o': '√ß√£o', '—Éo': '√£o', '–≥–≥': '√ß√£', '—É': '√£', '–π': '√©',
            '—å': '√≠', '–∑': '√ß', '—Ä': '√°', '—à': '√µ', '–∂': '√™',
            '—â': '√∫', '—ä': '√≥', '—é': '√ª', '—è': '√º'
        }
        
        normalized = text
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
            
        return normalized.strip()

    def find_available_file(self, file_variations: List[str]) -> Optional[str]:
        """Encontra qual varia√ß√£o do arquivo est√° dispon√≠vel"""
        for file_name in file_variations:
            if Path(file_name).exists():
                return file_name
        return None

    def get_nacionalidade_id(self, nome: str) -> Optional[int]:
        """Mapeia nome de nacionalidade para ID"""
        if pd.isna(nome) or nome == '':
            return None
            
        nome_norm = self.normalize_text(str(nome).strip())
        
        mapping = {
            'Popula√ß√£o residente': 14, 'Nacionalidade portuguesa': 12,
            'Nacionalidade estrangeira': 11, 'Brasil': 4, 'Angola': 2,
            'Cabo Verde': 5, 'Reino Unido': 15, 'Ucr√¢nia': 18, 'Fran√ßa': 8,
            'China': 6, 'Guin√©-Bissau': 9, '√çndia': 19, 'Rom√©nia': 16,
            'It√°lia': 10, 'Nepal': 13, 'Espanha': 7, 'Alemanha': 1,
            'S√£o Tom√© e Pr√≠ncipe': 17, 'Ap√°tridas': 3
        }
        
        return mapping.get(nome_norm)

    # ========================================================================
    # EXTRA√á√ÉO E LIMPEZA
    # ========================================================================

    def clean_dataframe(self, df: pd.DataFrame, file_name: str) -> pd.DataFrame:
        """Limpa e padroniza DataFrame"""
        self.logger.info(f"üßπ Limpando {file_name}...")
        
        df_clean = df.copy()
        
        # Remover linhas vazias
        df_clean = df_clean.dropna(how='all')
        
        # Filtrar linhas de metadados
        mask = df_clean.iloc[:, 0].astype(str).str.contains(
            'Quadro|Fonte:|Total|Popula√ß√£o empregada|N√≠vel|NUTS', 
            case=False, na=False
        )
        df_clean = df_clean[~mask]
        
        # Filtrar primeira coluna inv√°lida
        df_clean = df_clean[df_clean.iloc[:, 0].notna()]
        df_clean = df_clean[~df_clean.iloc[:, 0].astype(str).isin(['0', 'nan', ''])]
        
        # Normalizar primeira coluna
        df_clean.iloc[:, 0] = df_clean.iloc[:, 0].apply(self.normalize_text)
        
        # Converter colunas num√©ricas
        for col_idx in range(1, len(df_clean.columns)):
            if df_clean.iloc[:, col_idx].dtype == 'object':
                df_clean.iloc[:, col_idx] = (df_clean.iloc[:, col_idx]
                    .astype(str).str.replace(' ', '').str.replace(',', '.'))
                df_clean.iloc[:, col_idx] = pd.to_numeric(
                    df_clean.iloc[:, col_idx], errors='coerce').fillna(0)
        
        self.logger.info(f"‚úÖ {file_name}: {len(df)} ‚Üí {len(df_clean)} registros")
        return df_clean

    def load_reference_tables(self) -> None:
        """Carrega tabelas de refer√™ncia existentes"""
        try:
            ref_files = {
                'Nacionalidade': 'Nacionalidade.csv',
                'Sexo': 'Sexo.csv',
                'PopulacaoResidente': 'PopulacaoResidente.csv',
                'NivelEducacao': 'NivelEducacao.csv'
            }
            
            for name, file in ref_files.items():
                try:
                    df = pd.read_csv(file, encoding='utf-8')
                    self.reference_tables[name] = df
                    self.logger.info(f"‚úÖ {name}: {len(df)} registros")
                except FileNotFoundError:
                    self.logger.warning(f"‚ö†Ô∏è {file} n√£o encontrado - criando padr√£o")
                    self._create_minimal_reference(name)
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao carregar refer√™ncias: {e}")
            self._create_minimal_reference()

    def _create_minimal_reference(self, table_name: str = None) -> None:
        """Cria tabelas de refer√™ncia m√≠nimas"""
        if table_name == 'Nacionalidade' or table_name is None:
            self.reference_tables['Nacionalidade'] = pd.DataFrame({
                'nacionalidade_id': range(1, 20),
                'nome_nacionalidade': [
                    'Alemanha', 'Angola', 'Ap√°tridas', 'Brasil', 'Cabo Verde',
                    'China', 'Espanha', 'Fran√ßa', 'Guin√©-Bissau', 'It√°lia',
                    'Nacionalidade estrangeira', 'Nacionalidade portuguesa',
                    'Nepal', 'Popula√ß√£o residente', 'Reino Unido', 'Rom√©nia',
                    'S√£o Tom√© e Pr√≠ncipe', 'Ucr√¢nia', '√çndia'
                ]
            })
            
        if table_name == 'Sexo' or table_name is None:
            self.reference_tables['Sexo'] = pd.DataFrame({
                'sexo_id': [1, 2, 3],
                'tipo_sexo': ['HM', 'H', 'M']
            })
            
        if table_name == 'PopulacaoResidente' or table_name is None:
            self.reference_tables['PopulacaoResidente'] = pd.DataFrame({
                'populacao_id': [1, 2],
                'total_populacao': [21130491, 21453772],
                'ano_referencia': [2021, 2011]
            })
            
        if table_name == 'NivelEducacao' or table_name is None:
            self.reference_tables['NivelEducacao'] = pd.DataFrame({
                'nivel_educacao_id': [1, 2, 3, 4, 5, 6, 7],
                'nome_nivel': [
                    'Sem n√≠vel de ensino', 'Ensino B√°sico 1¬∫ ciclo',
                    'Ensino B√°sico 2¬∫ ciclo', 'Ensino B√°sico 3¬∫ ciclo',
                    'Ensino B√°sico', 'Ensino Secund√°rio/p√≥s-secund√°rio',
                    'Ensino Superior'
                ]
            })

    def extract_data(self) -> None:
        """Extrai dados de todos os arquivos CSV"""
        self.logger.info("=" * 60)
        self.logger.info("üìÇ FASE 1: EXTRA√á√ÉO DE DADOS")
        self.logger.info("=" * 60)
        
        for key, variations in self.input_files.items():
            try:
                found_file = self.find_available_file(variations)
                
                if not found_file:
                    self.logger.error(f"‚ùå {key}: Nenhuma varia√ß√£o encontrada")
                    continue
                
                self.logger.info(f"üìÑ Processando: {found_file}")
                
                # Tentar diferentes encodings
                df = None
                for encoding in ['utf-8', 'latin1', 'cp1252']:
                    try:
                        df = pd.read_csv(found_file, encoding=encoding, header=None)
                        break
                    except UnicodeDecodeError:
                        continue
                
                if df is None:
                    raise Exception(f"Erro de encoding em {found_file}")
                
                df_clean = self.clean_dataframe(df, found_file)
                
                if len(df_clean) == 0:
                    self.logger.warning(f"‚ö†Ô∏è {found_file}: 0 registros ap√≥s limpeza!")
                    continue
                
                self.raw_data[key] = df_clean
                self.statistics['files_processed'] += 1
                self.statistics['records_input'] += len(df_clean)
                
            except Exception as e:
                error_msg = f"‚ùå Erro em {key}: {e}"
                self.logger.error(error_msg)
                self.statistics['validation_errors'].append(error_msg)

    # ========================================================================
    # CRIA√á√ÉO DE TABELAS DIMENSIONAIS
    # ========================================================================

    def create_dimensional_tables(self) -> None:
        """Cria todas as tabelas dimensionais"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("üìä FASE 2: CRIA√á√ÉO DE TABELAS DIMENSIONAIS")
        self.logger.info("=" * 60)
        
        dims = [
            ('CondicaoEconomica', self._create_condicao_economica),
            ('GrupoProfissional', self._create_grupo_profissional),
            ('ProfissaoDigito1', self._create_profissao_digito1),
            ('SetorEconomico', self._create_setor_economico),
            ('SituacaoProfissional', self._create_situacao_profissional),
            ('FonteRendimento', self._create_fonte_rendimento),
            ('RegiaoNUTS', self._create_regiao_nuts)
        ]
        
        for name, func in dims:
            try:
                func()
                self.logger.info(f"‚úÖ {name}: {len(self.dimensional_tables[name])} registros")
            except Exception as e:
                self.logger.error(f"‚ùå Erro em {name}: {e}")

    def _create_condicao_economica(self) -> None:
        """CondicaoEconomica"""
        self.dimensional_tables['CondicaoEconomica'] = pd.DataFrame([
            {'condicao_id': 1, 'nome_condicao': 'Total', 'categoria': 'Total'},
            {'condicao_id': 2, 'nome_condicao': 'Ativa', 'categoria': 'Ativa'},
            {'condicao_id': 3, 'nome_condicao': 'Empregada', 'categoria': 'Ativa'},
            {'condicao_id': 4, 'nome_condicao': 'Desempregada', 'categoria': 'Ativa'},
            {'condicao_id': 5, 'nome_condicao': 'Inativa', 'categoria': 'Inativa'},
            {'condicao_id': 6, 'nome_condicao': 'Popula√ß√£o com menos de 15 anos', 'categoria': 'Inativa'},
            {'condicao_id': 7, 'nome_condicao': 'Estudantes', 'categoria': 'Inativa'},
            {'condicao_id': 8, 'nome_condicao': 'Dom√©sticos', 'categoria': 'Inativa'},
            {'condicao_id': 9, 'nome_condicao': 'Reformados', 'categoria': 'Inativa'},
            {'condicao_id': 10, 'nome_condicao': 'Incapacitados para o trabalho', 'categoria': 'Inativa'},
            {'condicao_id': 11, 'nome_condicao': 'Outra situa√ß√£o', 'categoria': 'Inativa'}
        ])

    def _create_grupo_profissional(self) -> None:
        """GrupoProfissional"""
        grupos = []
        descs = [
            'Profiss√µes das For√ßas Armadas',
            'Representantes do poder legislativo e de √≥rg√£os executivos, dirigentes, directores e gestores executivos',
            'Especialistas das actividades intelectuais e cient√≠ficas',
            'T√©cnicos e profiss√µes de n√≠vel interm√©dio',
            'Pessoal administrativo',
            'Trabalhadores dos servi√ßos pessoais, de protec√ß√£o e seguran√ßa e vendedores',
            'Agricultores e trabalhadores qualificados da agricultura, da pesca e da floresta',
            'Trabalhadores qualificados da ind√∫stria, constru√ß√£o e art√≠fices',
            'Operadores de instala√ß√µes e m√°quinas e trabalhadores da montagem',
            'Trabalhadores n√£o qualificados'
        ]
        for i, desc in enumerate(descs):
            grupos.append({'grupo_prof_id': i, 'codigo_grande_grupo': str(i), 'descricao': desc})
        
        self.dimensional_tables['GrupoProfissional'] = pd.DataFrame(grupos)

    def _create_profissao_digito1(self) -> None:
        """ProfissaoDigito1 (id√™ntico a GrupoProfissional)"""
        grupos = []
        descs = [
            'Profiss√µes das For√ßas Armadas',
            'Representantes do poder legislativo e de √≥rg√£os executivos, dirigentes, directores e gestores executivos',
            'Especialistas das actividades intelectuais e cient√≠ficas',
            'T√©cnicos e profiss√µes de n√≠vel interm√©dio',
            'Pessoal administrativo',
            'Trabalhadores dos servi√ßos pessoais, de protec√ß√£o e seguran√ßa e vendedores',
            'Agricultores e trabalhadores qualificados da agricultura, da pesca e da floresta',
            'Trabalhadores qualificados da ind√∫stria, constru√ß√£o e art√≠fices',
            'Operadores de instala√ß√µes e m√°quinas e trabalhadores da montagem',
            'Trabalhadores n√£o qualificados'
        ]
        for i, desc in enumerate(descs):
            grupos.append({'prof_digito1_id': i, 'codigo_digito1': str(i), 'descricao': desc})
        
        self.dimensional_tables['ProfissaoDigito1'] = pd.DataFrame(grupos)

    def _create_setor_economico(self) -> None:
        """SetorEconomico"""
        setores = []
        cae_letters = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U']
        cae_descs = [
            'Agricultura, produ√ß√£o animal, ca√ßa, floresta e pesca',
            'Ind√∫strias extractivas',
            'Ind√∫strias transformadoras',
            'Electricidade, g√°s, vapor, √°gua quente e fria e ar frio',
            'Capta√ß√£o, tratamento e distribui√ß√£o de √°gua; saneamento, gest√£o de res√≠duos e despolui√ß√£o',
            'Constru√ß√£o',
            'Com√©rcio por grosso e a retalho; repara√ß√£o de ve√≠culos autom√≥veis e motociclos',
            'Transportes e armazenagem',
            'Alojamento, restaura√ß√£o e similares',
            'Actividades de informa√ß√£o e de comunica√ß√£o',
            'Actividades financeiras e de seguros',
            'Actividades imobili√°rias',
            'Actividades de consultoria, cient√≠ficas, t√©cnicas e similares',
            'Actividades administrativas e dos servi√ßos de apoio',
            'Administra√ß√£o P√∫blica e Defesa; Seguran√ßa Social Obrigat√≥ria',
            'Educa√ß√£o',
            'Actividades de sa√∫de humana e apoio social',
            'Actividades art√≠sticas, de espect√°culos, desportivas e recreativas',
            'Outras actividades de servi√ßos',
            'Atividades das fam√≠lias empregadoras de pessoal dom√©stico',
            'Actividades dos organismos internacionais e outras institui√ß√µes extra-territoriais'
        ]
        
        for i, (cod, desc) in enumerate(zip(cae_letters, cae_descs)):
            setores.append({'setor_id': i+1, 'codigo_cae': cod, 'descricao': desc, 'agregado': False})
        
        # Setores agregados
        setores.extend([
            {'setor_id': 22, 'codigo_cae': 'AGR', 'descricao': 'Agricultura (Sec√ß√£o A)', 'agregado': True},
            {'setor_id': 23, 'codigo_cae': 'IND', 'descricao': 'Ind√∫stria (Sec√ß√£o B-E)', 'agregado': True},
            {'setor_id': 24, 'codigo_cae': 'CON', 'descricao': 'Constru√ß√£o (Sec√ß√£o F)', 'agregado': True},
            {'setor_id': 25, 'codigo_cae': 'COM', 'descricao': 'Com√©rcio (Sec√ß√£o G-J)', 'agregado': True},
            {'setor_id': 26, 'codigo_cae': 'FIN', 'descricao': 'Atividades financeiras e imobili√°rias (Sec√ß√£o K-L)', 'agregado': True},
            {'setor_id': 27, 'codigo_cae': 'SER', 'descricao': 'Outras atividades de servi√ßos (Sec√ß√£o M-U)', 'agregado': True}
        ])
        
        self.dimensional_tables['SetorEconomico'] = pd.DataFrame(setores)

    def _create_situacao_profissional(self) -> None:
        """SituacaoProfissional"""
        self.dimensional_tables['SituacaoProfissional'] = pd.DataFrame([
            {'situacao_id': 1, 'nome_situacao': 'Empregador/patr√£o'},
            {'situacao_id': 2, 'nome_situacao': 'Trabalhador por conta pr√≥pria'},
            {'situacao_id': 3, 'nome_situacao': 'Trabalhador por conta de outrem'},
            {'situacao_id': 4, 'nome_situacao': 'Outra situa√ß√£o'}
        ])

    def _create_fonte_rendimento(self) -> None:
        """FonteRendimento"""
        self.dimensional_tables['FonteRendimento'] = pd.DataFrame([
            {'fonte_id': 1, 'nome_fonte': 'Rendimento do trabalho'},
            {'fonte_id': 2, 'nome_fonte': 'Pens√£o / Reforma'},
            {'fonte_id': 3, 'nome_fonte': 'Rendimento de propriedade /empresa'},
            {'fonte_id': 4, 'nome_fonte': 'Subs√≠dios tempor√°rios (desemprego, RSI, ...)'},
            {'fonte_id': 5, 'nome_fonte': 'A cargo da fam√≠lia'},
            {'fonte_id': 6, 'nome_fonte': 'Outra'}
        ])

    def _create_regiao_nuts(self) -> None:
        """RegiaoNUTS"""
        self.dimensional_tables['RegiaoNUTS'] = pd.DataFrame([
            {'nuts_id': 1, 'codigo_nuts': 'PT', 'nome_regiao': 'Portugal'},
            {'nuts_id': 2, 'codigo_nuts': 'PT11', 'nome_regiao': 'Norte'},
            {'nuts_id': 3, 'codigo_nuts': 'PT16', 'nome_regiao': 'Centro'},
            {'nuts_id': 4, 'codigo_nuts': 'PT17', 'nome_regiao': 'AM Lisboa'},
            {'nuts_id': 5, 'codigo_nuts': 'PT18', 'nome_regiao': 'Alentejo'},
            {'nuts_id': 6, 'codigo_nuts': 'PT15', 'nome_regiao': 'Algarve'},
            {'nuts_id': 7, 'codigo_nuts': 'PT20', 'nome_regiao': 'RA A√ßores'},
            {'nuts_id': 8, 'codigo_nuts': 'PT30', 'nome_regiao': 'RA Madeira'}
        ])

    # ========================================================================
    # CRIA√á√ÉO DE TABELAS DE FATO
    # ========================================================================

    def create_fact_tables(self) -> None:
        """Cria todas as tabelas de fato"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("üìà FASE 3: CRIA√á√ÉO DE TABELAS DE FATO")
        self.logger.info("=" * 60)
        
        facts = [
            ('PopulacaoPorCondicao', self._create_populacao_condicao, 'Q3.1'),
            ('EmpregadosPorProfissao', self._create_empregados_profissao, 'Q3.2'),
            ('EmpregadosPorSetor', self._create_empregados_setor, 'Q3.3'),
            ('EmpregadosPorSituacao', self._create_empregados_situacao, 'Q3.4'),
            ('EmpregadosProfSexo', self._create_empregados_prof_sexo, 'Q20'),
            ('EmpregadosRegiaoSetor', self._create_empregados_regiao_setor, 'Q21'),
            ('PopulacaoTrabalhoEscolaridade', self._create_pop_trabalho_esc, 'Q23'),
            ('PopulacaoRendimentoRegiao', self._create_pop_rendimento_regiao, 'Q24')
        ]
        
        for name, func, source in facts:
            try:
                if source in self.raw_data:
                    func()
                    recs = len(self.fact_tables.get(name, []))
                    self.logger.info(f"‚úÖ {name}: {recs} registros")
                else:
                    self.logger.warning(f"‚ö†Ô∏è {name}: Dados {source} ausentes")
            except Exception as e:
                self.logger.error(f"‚ùå Erro em {name}: {e}")

    def _create_populacao_condicao(self) -> None:
        """PopulacaoPorCondicao de Q3.1"""
        df = self.raw_data['Q3.1']
        records = []
        record_id = 1
        
        for idx, row in df.iterrows():
            nac_id = self.get_nacionalidade_id(row.iloc[0])
            if not nac_id:
                continue
            
            for cond_id in range(1, 12):
                if cond_id < len(row):
                    qtd = row.iloc[cond_id] if not pd.isna(row.iloc[cond_id]) else 0
                    if qtd > 0:
                        records.append({
                            'populacao_cond_id': record_id,
                            'populacao_id': 1,
                            'nacionalidade_id': nac_id,
                            'condicao_id': cond_id,
                            'quantidade': int(qtd),
                            'percentual': 0.0
                        })
                        record_id += 1
        
        self.fact_tables['PopulacaoPorCondicao'] = pd.DataFrame(records)

    def _create_empregados_profissao(self) -> None:
        """EmpregadosPorProfissao de Q3.2"""
        df = self.raw_data['Q3.2']
        records = []
        record_id = 1
        
        for idx, row in df.iterrows():
            nac_id = self.get_nacionalidade_id(row.iloc[0])
            if not nac_id:
                continue
            
            for prof_id in range(10):
                col_idx = prof_id + 2
                if col_idx < len(row):
                    qtd = row.iloc[col_idx] if not pd.isna(row.iloc[col_idx]) else 0
                    if qtd > 0:
                        records.append({
                            'emp_prof_id': record_id,
                            'nacionalidade_id': nac_id,
                            'grupo_prof_id': prof_id,
                            'quantidade': int(qtd)
                        })
                        record_id += 1
        
        self.fact_tables['EmpregadosPorProfissao'] = pd.DataFrame(records)

    def _create_empregados_setor(self) -> None:
        """EmpregadosPorSetor de Q3.3"""
        df = self.raw_data['Q3.3']
        records = []
        record_id = 1
        
        for idx, row in df.iterrows():
            nac_id = self.get_nacionalidade_id(row.iloc[0])
            if not nac_id:
                continue
            
            for setor_id in range(1, 22):
                col_idx = setor_id + 1
                if col_idx < len(row):
                    qtd = row.iloc[col_idx] if not pd.isna(row.iloc[col_idx]) else 0
                    if qtd > 0:
                        records.append({
                            'emp_setor_id': record_id,
                            'nacionalidade_id': nac_id,
                            'setor_id': setor_id,
                            'quantidade': int(qtd)
                        })
                        record_id += 1
        
        self.fact_tables['EmpregadosPorSetor'] = pd.DataFrame(records)

    def _create_empregados_situacao(self) -> None:
        """EmpregadosPorSituacao de Q3.4"""
        df = self.raw_data['Q3.4']
        records = []
        record_id = 1
        
        for idx, row in df.iterrows():
            nac_id = self.get_nacionalidade_id(row.iloc[0])
            if not nac_id:
                continue
            
            for sit_id in range(1, 5):
                col_idx = sit_id + 1
                if col_idx < len(row):
                    qtd = row.iloc[col_idx] if not pd.isna(row.iloc[col_idx]) else 0
                    if qtd > 0:
                        records.append({
                            'emp_situacao_id': record_id,
                            'nacionalidade_id': nac_id,
                            'situacao_id': sit_id,
                            'quantidade': int(qtd)
                        })
                        record_id += 1
        
        self.fact_tables['EmpregadosPorSituacao'] = pd.DataFrame(records)

    def _create_empregados_prof_sexo(self) -> None:
        """EmpregadosProfSexo de Q20"""
        df = self.raw_data['Q20']
        records = []
        record_id = 1
        
        prof_keywords = [
            'For√ßas Armadas', 'poder legislativo', 'Especialistas', 'T√©cnicos',
            'administrativo', 'servi√ßos pessoais', 'Agricultores',
            'ind√∫stria', 'Operadores', 'n√£o qualificados'
        ]
        
        for idx, row in df.iterrows():
            prof_nome = str(row.iloc[0])
            prof_id = None
            
            for i, keyword in enumerate(prof_keywords):
                if keyword.lower() in prof_nome.lower():
                    prof_id = i
                    break
            
            if prof_id is None:
                continue
            
            qtd_hm = row.iloc[1] if len(row) > 1 and not pd.isna(row.iloc[1]) else 0
            qtd_h = row.iloc[2] if len(row) > 2 and not pd.isna(row.iloc[2]) else 0
            qtd_m = row.iloc[3] if len(row) > 3 and not pd.isna(row.iloc[3]) else 0
            
            if qtd_h > 0 or qtd_m > 0:
                records.append({
                    'emp_prof_sexo_id': record_id,
                    'prof_digito1_id': prof_id,
                    'sexo_id': 1,
                    'quantidade_homens': int(qtd_h),
                    'quantidade_mulheres': int(qtd_m)
                })
                record_id += 1
        
        self.fact_tables['EmpregadosProfSexo'] = pd.DataFrame(records)

    def _create_empregados_regiao_setor(self) -> None:
        """EmpregadosRegiaoSetor de Q21"""
        df = self.raw_data['Q21']
        records = []
        record_id = 1
        
        regiao_map = {
            'Portugal': 1, 'Norte': 2, 'Centro': 3, 'AM Lisboa': 4,
            'Alentejo': 5, 'Algarve': 6, 'RA A√ßores': 7, 'RA Madeira': 8
        }
        
        for idx, row in df.iterrows():
            nuts_id = regiao_map.get(str(row.iloc[0]))
            if not nuts_id:
                continue
            
            for setor_idx in range(6):
                col_idx = setor_idx + 2
                if col_idx < len(row):
                    qtd = row.iloc[col_idx] if not pd.isna(row.iloc[col_idx]) else 0
                    if qtd > 0:
                        records.append({
                            'emp_regiao_setor_id': record_id,
                            'nuts_id': nuts_id,
                            'setor_id': setor_idx + 22,
                            'quantidade': int(qtd)
                        })
                        record_id += 1
        
        self.fact_tables['EmpregadosRegiaoSetor'] = pd.DataFrame(records)

    def _create_pop_trabalho_esc(self) -> None:
        """PopulacaoTrabalhoEscolaridade de Q23"""
        df = self.raw_data['Q23']
        records = []
        record_id = 1
        
        nivel_map = {
            'Sem n√≠vel': 1, 'B√°sico 1¬∫': 2, 'B√°sico 2¬∫': 3,
            'B√°sico 3¬∫': 4, 'Secund√°rio': 6, 'Superior': 7
        }
        
        condicoes = ['Empregada', 'Desempregada', 'N√£o activa']
        
        for idx, row in df.iterrows():
            nivel_nome = str(row.iloc[0])
            nivel_id = None
            
            for key, nid in nivel_map.items():
                if key.lower() in nivel_nome.lower():
                    nivel_id = nid
                    break
            
            if not nivel_id:
                continue
            
            for cond_idx, condicao in enumerate(condicoes):
                base_col = cond_idx * 3 + 1
                
                if base_col + 2 < len(row):
                    qtd_hm = row.iloc[base_col] if not pd.isna(row.iloc[base_col]) else 0
                    qtd_h = row.iloc[base_col + 1] if not pd.isna(row.iloc[base_col + 1]) else 0
                    qtd_m = row.iloc[base_col + 2] if not pd.isna(row.iloc[base_col + 2]) else 0
                    
                    if qtd_hm > 0:
                        records.append({
                            'pop_trab_esc_id': record_id,
                            'nivel_educacao_id': nivel_id,
                            'sexo_id': 1,
                            'condicao_trabalho': condicao,
                            'quantidade_hm': int(qtd_hm),
                            'quantidade_h': int(qtd_h),
                            'quantidade_m': int(qtd_m)
                        })
                        record_id += 1
        
        self.fact_tables['PopulacaoTrabalhoEscolaridade'] = pd.DataFrame(records)

    def _create_pop_rendimento_regiao(self) -> None:
        """PopulacaoRendimentoRegiao de Q24"""
        df = self.raw_data['Q24']
        records = []
        record_id = 1
        
        regiao_map = {
            'Portugal': 1, 'Norte': 2, 'Centro': 3, 'AM Lisboa': 4,
            'Alentejo': 5, 'Algarve': 6, 'RA A√ßores': 7, 'RA Madeira': 8
        }
        
        for idx, row in df.iterrows():
            nuts_id = regiao_map.get(str(row.iloc[0]))
            if not nuts_id:
                continue
            
            for fonte_id in range(1, 7):
                col_idx = fonte_id + 1
                if col_idx < len(row):
                    qtd = row.iloc[col_idx] if not pd.isna(row.iloc[col_idx]) else 0
                    if qtd > 0:
                        records.append({
                            'pop_rend_reg_id': record_id,
                            'nuts_id': nuts_id,
                            'fonte_id': fonte_id,
                            'quantidade': int(qtd)
                        })
                        record_id += 1
        
        self.fact_tables['PopulacaoRendimentoRegiao'] = pd.DataFrame(records)

    # ========================================================================
    # VALIDA√á√ÉO
    # ========================================================================

    def validate_all(self) -> Dict:
        """Valida integridade referencial"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("‚úì FASE 4: VALIDA√á√ÉO DE INTEGRIDADE")
        self.logger.info("=" * 60)
        
        results = {'errors': [], 'warnings': [], 'passed': []}
        
        # Validar nacionalidades
        nac_ref = set(self.reference_tables['Nacionalidade']['nacionalidade_id'])
        for name, df in self.fact_tables.items():
            if 'nacionalidade_id' in df.columns:
                invalid = set(df['nacionalidade_id']) - nac_ref
                if invalid:
                    results['errors'].append(f"{name}: IDs inv√°lidos {invalid}")
                else:
                    results['passed'].append(f"{name}: Nacionalidades ‚úì")
        
        # Validar sexos
        sex_ref = set(self.reference_tables['Sexo']['sexo_id'])
        for name, df in self.fact_tables.items():
            if 'sexo_id' in df.columns:
                invalid = set(df['sexo_id']) - sex_ref
                if invalid:
                    results['errors'].append(f"{name}: Sexo IDs inv√°lidos {invalid}")
                else:
                    results['passed'].append(f"{name}: Sexos ‚úì")
        
        # Validar n√£o-negativos
        for name, df in {**self.dimensional_tables, **self.fact_tables}.items():
            for col in df.select_dtypes(include=[np.number]).columns:
                if not col.endswith('_id'):
                    if (df[col] < 0).sum() > 0:
                        results['errors'].append(f"{name}.{col}: Valores negativos")
                    else:
                        results['passed'].append(f"{name}.{col}: N√£o-negativos ‚úì")
        
        self.logger.info(f"‚úÖ Passou: {len(results['passed'])}")
        self.logger.info(f"‚ö†Ô∏è Avisos: {len(results['warnings'])}")
        self.logger.info(f"‚ùå Erros: {len(results['errors'])}")
        
        return results

    # ========================================================================
    # SALVAMENTO
    # ========================================================================

    def save_all_tables(self) -> None:
        """Salva todas as tabelas"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("üíæ FASE 5: SALVAMENTO DE TABELAS")
        self.logger.info("=" * 60)
        
        for name, df in self.dimensional_tables.items():
            filename = f"{name}.csv"
            df.to_csv(filename, index=False, encoding='utf-8')
            self.statistics['records_output'] += len(df)
            self.logger.info(f"üíæ {filename}: {len(df)} registros")
        
        for name, df in self.fact_tables.items():
            filename = f"{name}.csv"
            df.to_csv(filename, index=False, encoding='utf-8')
            self.statistics['records_output'] += len(df)
            self.logger.info(f"üíæ {filename}: {len(df)} registros")
        
        self._create_index()

    def _create_index(self) -> None:
        """Cria √≠ndice de tabelas"""
        index = []
        
        for name, df in self.dimensional_tables.items():
            index.append({
                'arquivo': f"{name}.csv",
                'tabela': name,
                'tipo': 'Dimensional',
                'registros': len(df),
                'colunas': len(df.columns)
            })
        
        for name, df in self.fact_tables.items():
            index.append({
                'arquivo': f"{name}.csv",
                'tabela': name,
                'tipo': 'Fato',
                'registros': len(df),
                'colunas': len(df.columns)
            })
        
        pd.DataFrame(index).to_csv('INDICE_TABELAS_LABORAIS.csv', index=False, encoding='utf-8')
        self.logger.info("üìã INDICE_TABELAS_LABORAIS.csv criado")

    def generate_report(self) -> str:
        """Gera relat√≥rio final"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("üìä FASE 6: RELAT√ìRIO FINAL")
        self.logger.info("=" * 60)
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        lines = [
            "RELAT√ìRIO ETL - DADOS LABORAIS CENSOS 2021",
            f"Timestamp: {timestamp}",
            "=" * 60,
            "",
            "ESTAT√çSTICAS:",
            f"Arquivos processados: {self.statistics['files_processed']}/8",
            f"Registros entrada: {self.statistics['records_input']:,}",
            f"Registros sa√≠da: {self.statistics['records_output']:,}",
            f"Tabelas dimensionais: {len(self.dimensional_tables)}",
            f"Tabelas de fato: {len(self.fact_tables)}",
            "",
            "ARQUIVOS GERADOS:"
        ]
        
        for name in self.dimensional_tables.keys():
            lines.append(f"  {name}.csv")
        for name in self.fact_tables.keys():
            lines.append(f"  {name}.csv")
        
        lines.extend(["", "‚úÖ PROCESSAMENTO CONCLU√çDO"])
        
        report = "\n".join(lines)
        
        with open('RELATORIO_ESTATISTICAS.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.logger.info("üìä RELATORIO_ESTATISTICAS.txt criado")
        return report

    # ========================================================================
    # EXECU√á√ÉO PRINCIPAL
    # ========================================================================

    def run_etl(self) -> bool:
        """Executa ETL completo"""
        try:
            self.logger.info("\n" + "üöÄ" * 30)
            self.logger.info("PROCESSO ETL LABORAL - CENSOS 2021 PORTUGAL")
            self.logger.info("üöÄ" * 30 + "\n")
            
            self.load_reference_tables()
            self.extract_data()
            
            if not self.raw_data:
                self.logger.error("‚ùå Nenhum arquivo carregado!")
                return False
            
            self.create_dimensional_tables()
            self.create_fact_tables()
            
            validation = self.validate_all()
            self.statistics['validation_errors'].extend(validation['errors'])
            self.statistics['warnings'].extend(validation['warnings'])
            
            self.save_all_tables()
            self.generate_report()
            
            success = len(self.statistics['validation_errors']) == 0
            
            if success:
                self.logger.info("\n" + "üéâ" * 30)
                self.logger.info("ETL CONCLU√çDO COM SUCESSO!")
                self.logger.info("üéâ" * 30)
            else:
                self.logger.warning(f"\n‚ö†Ô∏è ETL conclu√≠do com {len(self.statistics['validation_errors'])} erros")
            
            return success
            
        except Exception as e:
            self.logger.error(f"‚ùå ERRO CR√çTICO: {e}")
            return False

# ============================================================================
# FUN√á√ïES GOOGLE COLAB
# ============================================================================

def setup_colab():
    """Setup para Google Colab"""
    print("üîß Configurando ambiente...")
    try:
        import pandas as pd
        import numpy as np
        print("‚úÖ Depend√™ncias OK")
    except:
        import subprocess, sys
        subprocess.check_call([sys.executable, "-m", "pip", "install", "pandas", "numpy"])
    print("üéØ Pronto!")

def upload_files():
    """Upload de arquivos no Colab"""
    try:
        from google.colab import files
        print("üìÅ Fa√ßa upload dos 8 arquivos CSV:")
        print("Q3.1, Q3.2, Q3.3, Q3.4, Q20, Q21, Q23, Q24")
        uploaded = files.upload()
        print(f"‚úÖ {len(uploaded)} arquivos carregados")
        return list(uploaded.keys())
    except:
        print("‚ö†Ô∏è Execute no Google Colab")
        return []

def download_results():
    """Download dos resultados"""
    try:
        from google.colab import files
        import zipfile
        
        print("üì¶ Criando ZIP...")
        
        outputs = []
        for file in Path('.').glob('*.csv'):
            if any(file.name.startswith(x) for x in ['Condicao', 'Grupo', 'Profissao', 'Setor', 'Situacao', 'Fonte', 'Regiao', 'Populacao', 'Empregados', 'INDICE']):
                outputs.append(file.name)
        
        for file in ['RELATORIO_ESTATISTICAS.txt', 'etl_laboral_log.txt']:
            if Path(file).exists():
                outputs.append(file)
        
        with zipfile.ZipFile('resultados_etl_laboral.zip', 'w') as zipf:
            for f in outputs:
                zipf.write(f)
                print(f"  ‚úÖ {f}")
        
        print(f"\nüì• Baixando {len(outputs)} arquivos...")
        files.download('resultados_etl_laboral.zip')
        print("üéâ Download conclu√≠do!")
        
    except:
        print("üìÇ Arquivos salvos no diret√≥rio atual")

def run_colab_etl():
    """Fun√ß√£o principal para Colab"""
    print("üáµüáπ ETL DADOS LABORAIS CENSOS 2021 PORTUGAL")
    print("=" * 50)
    
    setup_colab()
    upload_files()
    
    print("\nüîÑ Processando...")
    processor = ETLLaboralProcessor()
    success = processor.run_etl()
    
    if success:
        download_results()
    
    return success

# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    try:
        import google.colab
        print("üîç Google Colab detectado")
        success = run_colab_etl()
    except:
        print("üñ•Ô∏è Execu√ß√£o local")
        processor = ETLLaboralProcessor()
        success = processor.run_etl()
    
    if success:
        print("\n" + "=" * 60)
        print("üéâ ETL CONCLU√çDO COM SUCESSO!")
        print("üìä Dataset laboral normalizado criado")
        print("üîó Pronto para an√°lises")
        print("=" * 60)
    else:
        print("\n‚ùå ETL FALHOU - Verifique os logs")
