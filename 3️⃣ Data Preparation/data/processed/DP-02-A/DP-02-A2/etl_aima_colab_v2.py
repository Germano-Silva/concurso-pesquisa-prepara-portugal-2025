"""
ETL AIMA/SEF para Google Colab - v2.0
Processa RIFA 2020-2022 e RMA 2023-2024
Conforme Diagrama ER: diagrama-er-completo-aima-integrado.mermaid

Autor: Cline - Concurso Prepara Portugal 2025
Execu√ß√£o: 100% Google Colab (Upload CSV ‚Üí Transform ‚Üí Download)
"""

# ========== SE√á√ÉO 1: INSTALA√á√ÉO E IMPORTS ==========
print("üì¶ Instalando depend√™ncias...")
!pip install pandas -q

import pandas as pd
import io
from google.colab import files
import warnings
warnings.filterwarnings('ignore')

print("‚úÖ Depend√™ncias instaladas!\n")

# ========== SE√á√ÉO 2: CONFIGURA√á√ïES GLOBAIS ==========
ANOS_CONFIG = {
    2020: 'RIFA',
    2021: 'RIFA',
    2022: 'RIFA',
    2023: 'RMA',
    2024: 'RMA'
}

TIPO_RELATORIO_MAP = {
    1: 'ConcessaoTitulos',
    2: 'PopulacaoEstrangeira',
    3: 'PopulacaoResidente'
}

SEXO_NORMALIZADO = {
    'Homens': 'M', 'Mulheres': 'F', 
    'homens': 'M', 'mulheres': 'F',
    'Masculino': 'M', 'Feminino': 'F'
}

# ========== SE√á√ÉO 3: FUN√á√ïES DE TRANSFORMA√á√ÉO ==========

def normalizar_coluna_sexo(valor):
    """Normaliza valores de sexo para M/F"""
    return SEXO_NORMALIZADO.get(valor, valor)

def parse_concessao_residencia(content_str, ano):
    """
    Transforma: concessao-titulos-residencia.csv
    Sa√≠da: ConcessoesPorNacionalidadeSexo (long format)
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    # Renomear colunas padronizadas
    col_map = {
        'NACIONALIDADES': 'nacionalidade_aima_raw',
        'NACIONALIDADE': 'nacionalidade_aima_raw',
        'Homens': 'homens', 'Mulheres': 'mulheres',
        'Masculino': 'homens', 'Feminino': 'mulheres'
    }
    df = df.rename(columns=col_map)
    
    # Melt para long format
    df_long = df.melt(
        id_vars=['nacionalidade_aima_raw'],
        value_vars=['homens', 'mulheres'],
        var_name='sexo_raw',
        value_name='quantidade'
    )
    
    df_long['sexo_raw'] = df_long['sexo_raw'].map({'homens': 'M', 'mulheres': 'F'})
    df_long['ano'] = ano
    df_long['fonte'] = ANOS_CONFIG[ano]
    df_long['tipo_relatorio'] = 1
    
    return df_long[['ano', 'fonte', 'tipo_relatorio', 'nacionalidade_aima_raw', 'sexo_raw', 'quantidade']]

def parse_populacao_estrangeira(content_str, ano):
    """
    Transforma: populacao-estrangeira-residente.csv
    Sa√≠da: PopulacaoEstrangeiraPorNacionalidadeSexo
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    col_map = {
        'NACIONALIDADES': 'nacionalidade_aima_raw',
        'Homens': 'homens', 'Mulheres': 'mulheres',
        'Masculino': 'homens', 'Feminino': 'mulheres'
    }
    df = df.rename(columns=col_map)
    
    df_long = df.melt(
        id_vars=['nacionalidade_aima_raw'],
        value_vars=['homens', 'mulheres'],
        var_name='sexo_raw',
        value_name='quantidade'
    )
    
    df_long['sexo_raw'] = df_long['sexo_raw'].map({'homens': 'M', 'mulheres': 'F'})
    df_long['ano'] = ano
    df_long['fonte'] = ANOS_CONFIG[ano]
    df_long['tipo_relatorio'] = 2
    
    return df_long[['ano', 'fonte', 'tipo_relatorio', 'nacionalidade_aima_raw', 'sexo_raw', 'quantidade']]

def parse_despachos_concessao(content_str, ano):
    """
    Transforma: concessao-titulos_despachos.csv
    Sa√≠da: ConcessoesPorDespacho
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    df = df.rename(columns={
        df.columns[0]: 'codigo_despacho',
        df.columns[1]: 'concessoes'
    })
    
    df['ano'] = ano
    df['fonte'] = ANOS_CONFIG[ano]
    df['tipo_relatorio'] = 1
    
    return df[['ano', 'fonte', 'tipo_relatorio', 'codigo_despacho', 'concessoes']]

def parse_despachos_descricao(content_str):
    """
    Transforma: despachos-descricao.csv
    Sa√≠da: Despacho (dimens√£o)
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    df = df.rename(columns={
        df.columns[0]: 'codigo_despacho',
        df.columns[1]: 'descricao'
    })
    
    return df[['codigo_despacho', 'descricao']]

def parse_distribuicao_etaria_concessoes(content_str, ano):
    """
    Transforma: concessao-titulos_distribuicao-etaria.csv
    Sa√≠da: DistribuicaoEtariaConcessoes
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    df = df.rename(columns={
        'FAIXA ETARIA': 'grupo_etario_raw',
        'Faixa Et√°ria': 'grupo_etario_raw',
        'Homens': 'homens', 'Mulheres': 'mulheres'
    })
    
    df_long = df.melt(
        id_vars=['grupo_etario_raw'],
        value_vars=['homens', 'mulheres'],
        var_name='sexo_raw',
        value_name='quantidade'
    )
    
    df_long['sexo_raw'] = df_long['sexo_raw'].map({'homens': 'M', 'mulheres': 'F'})
    df_long['ano'] = ano
    df_long['fonte'] = ANOS_CONFIG[ano]
    df_long['tipo_relatorio'] = 1
    
    return df_long[['ano', 'fonte', 'tipo_relatorio', 'grupo_etario_raw', 'sexo_raw', 'quantidade']]

def parse_motivos_concessao(content_str, ano):
    """
    Transforma: concessao-titulos_motivo.csv
    Sa√≠da: ConcessoesPorMotivoNacionalidade
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    # Identificar coluna pa√≠s
    pais_col = df.columns[0]
    motivo_cols = df.columns[2:]  # Pular 'Total'
    
    df_long = df.melt(
        id_vars=[pais_col],
        value_vars=motivo_cols,
        var_name='motivo_raw',
        value_name='total_motivo'
    )
    
    df_long['nacionalidade_aima_raw'] = df_long[pais_col]
    df_long['ano'] = ano
    df_long['fonte'] = ANOS_CONFIG[ano]
    
    return df_long[['ano', 'fonte', 'motivo_raw', 'nacionalidade_aima_raw', 'total_motivo']]

def parse_populacao_residente_etaria(content_str, ano):
    """
    Transforma: populacao-residente_distribuicao-etaria.csv
    Sa√≠da: PopulacaoResidenteEtaria
    """
    df = pd.read_csv(io.StringIO(content_str))
    df.columns = df.columns.str.strip()
    
    df = df.rename(columns={
        'FAIXA ETARIA': 'grupo_etario_raw',
        'Faixa Et√°ria': 'grupo_etario_raw',
        df.columns[-1]: 'total'
    })
    
    df['ano'] = ano
    df['fonte'] = ANOS_CONFIG[ano]
    df['tipo_relatorio'] = 3
    
    return df[['ano', 'fonte', 'tipo_relatorio', 'grupo_etario_raw', 'total']]

# ========== SE√á√ÉO 4: PROCESSAMENTO POR ANO ==========

def processar_ano(ano):
    """
    Solicita upload e processa todos CSVs de um ano espec√≠fico
    """
    fonte = ANOS_CONFIG[ano]
    print(f"\n{'='*60}")
    print(f"üìÖ ANO {ano} ({fonte})")
    print(f"{'='*60}")
    print(f"\nüì§ Fa√ßa upload dos CSVs de {fonte}{ano}:")
    print(f"   Exemplo: {fonte}{ano} - concessao-titulos-residencia.csv")
    print(f"   (Voc√™ pode selecionar m√∫ltiplos arquivos de uma vez)\n")
    
    uploaded = files.upload()
    dados_ano = {}
    
    print(f"\nüîÑ Processando {len(uploaded)} arquivo(s)...")
    
    for filename, file_bytes in uploaded.items():
        content = file_bytes.decode('utf-8')
        
        # Detectar tipo de arquivo e aplicar parsing
        if 'concessao-titulos-residencia' in filename.lower():
            dados_ano['concessoes_nac_sexo'] = parse_concessao_residencia(content, ano)
            print(f"  ‚úì Concess√µes por Nacionalidade/Sexo")
            
        elif 'populacao-estrangeira-residente' in filename.lower() and 'evolucao' not in filename.lower():
            dados_ano['pop_est_nac_sexo'] = parse_populacao_estrangeira(content, ano)
            print(f"  ‚úì Popula√ß√£o Estrangeira por Nacionalidade/Sexo")
            
        elif 'concessao-titulos_despachos' in filename.lower():
            dados_ano['concessoes_despacho'] = parse_despachos_concessao(content, ano)
            print(f"  ‚úì Concess√µes por Despacho")
            
        elif 'despachos-descricao' in filename.lower():
            dados_ano['despacho_dim'] = parse_despachos_descricao(content)
            print(f"  ‚úì Despachos (Dimens√£o)")
            
        elif 'concessao-titulos_distribuicao-etaria' in filename.lower():
            dados_ano['dist_etaria_conc'] = parse_distribuicao_etaria_concessoes(content, ano)
            print(f"  ‚úì Distribui√ß√£o Et√°ria de Concess√µes")
            
        elif 'concessao-titulos_motivo' in filename.lower():
            dados_ano['concessoes_motivo'] = parse_motivos_concessao(content, ano)
            print(f"  ‚úì Concess√µes por Motivo")
            
        elif 'populacao-residente-distribuicao-etaria' in filename.lower() or \
             'populacao-residente_distribuicao-etaria' in filename.lower():
            dados_ano['pop_res_etaria'] = parse_populacao_residente_etaria(content, ano)
            print(f"  ‚úì Popula√ß√£o Residente Et√°ria")
    
    print(f"\n‚úÖ {ano} processado: {len(dados_ano)} tabelas criadas")
    return dados_ano

# ========== SE√á√ÉO 5: CONSTRU√á√ÉO DE DIMENS√ïES ==========

def construir_dimensoes(todos_dados):
    """
    Constr√≥i tabelas de dimens√£o √∫nicas a partir dos dados de todos os anos
    """
    print(f"\n{'='*60}")
    print("üèóÔ∏è  CONSTRUINDO DIMENS√ïES GLOBAIS")
    print(f"{'='*60}\n")
    
    # AnoRelatorio
    ano_dim = pd.DataFrame(list(ANOS_CONFIG.items()), columns=['ano', 'fonte'])
    print(f"  ‚úì AnoRelatorio: {len(ano_dim)} linhas")
    
    # TipoRelatorio
    tipo_dim = pd.DataFrame(list(TIPO_RELATORIO_MAP.items()), columns=['tipo_id', 'tipo'])
    print(f"  ‚úì TipoRelatorio: {len(tipo_dim)} linhas")
    
    # Sexo (fixo)
    sexo_dim = pd.DataFrame([
        {'sexo_id': 1, 'tipo_sexo': 'M'},
        {'sexo_id': 2, 'tipo_sexo': 'F'}
    ])
    print(f"  ‚úì Sexo: {len(sexo_dim)} linhas")
    
    # Nacionalidade (DIMENS√ÉO COMPARTILHADA - solicitar CSV processado)
    print(f"\nüì§ Upload necess√°rio: Nacionalidade.csv (dimens√£o compartilhada)")
    print("   Localiza√ß√£o: 3Ô∏è‚É£ Data Preparation/data/processed/DP-01-A/Nacionalidade.csv")
    uploaded_nac = files.upload()
    
    if uploaded_nac:
        nac_file = list(uploaded_nac.keys())[0]
        nacionalidade_base = pd.read_csv(io.BytesIO(uploaded_nac[nac_file]))
        print(f"  ‚úì Nacionalidade (base): {len(nacionalidade_base)} linhas\n")
    else:
        print("  ‚ö†Ô∏è  Nacionalidade.csv n√£o carregado - criando base m√≠nima\n")
        nacionalidade_base = pd.DataFrame({
            'nacionalidade_id': [1],
            'nome_nacionalidade': ['Desconhecido'],
            'codigo_pais': ['XX'],
            'continente': ['Desconhecido']
        })
    
    # NacionalidadeAIMA (uni√£o de todas nacionalidades √∫nicas dos CSVs AIMA)
    nacs = []
    for ano_data in todos_dados.values():
        for tabela in ano_data.values():
            if 'nacionalidade_aima_raw' in tabela.columns:
                nacs.extend(tabela['nacionalidade_aima_raw'].unique())
    
    nacionalidade_aima_dim = pd.DataFrame({'nome_nacionalidade_aima': sorted(set(nacs))})
    nacionalidade_aima_dim['nacionalidade_aima_id'] = range(1, len(nacionalidade_aima_dim) + 1)
    
    # MAPEAMENTO: NacionalidadeAIMA -> Nacionalidade (FK)
    # Fazer merge fuzzy/manual mapping (simplified version)
    nacionalidade_aima_dim['nacionalidade_id'] = None  # FK placeholder
    # Nota: Mapeamento completo requer l√≥gica adicional ou tabela auxiliar
    
    print(f"  ‚úì NacionalidadeAIMA: {len(nacionalidade_aima_dim)} linhas (com FK para Nacionalidade)")
    
    # Despacho (uni√£o de todos despachos)
    despachos = []
    for ano_data in todos_dados.values():
        if 'despacho_dim' in ano_data:
            despachos.append(ano_data['despacho_dim'])
    despacho_dim = pd.concat(despachos, ignore_index=True).drop_duplicates('codigo_despacho')
    print(f"  ‚úì Despacho: {len(despacho_dim)} linhas")
    
    # MotivoConcessao (uni√£o de todos motivos)
    motivos = []
    for ano_data in todos_dados.values():
        if 'concessoes_motivo' in ano_data:
            motivos.extend(ano_data['concessoes_motivo']['motivo_raw'].unique())
    
    motivo_dim = pd.DataFrame({'motivo_raw': sorted(set(motivos))})
    motivo_dim['categoria'] = motivo_dim['motivo_raw'].map({
        'Reagrupamento Familiar': 'Familiar',
        'Atividade Profissional': 'Profissional',
        'Estudo': 'Educacional',
        'CRs': 'Outro',
        'Certificado de Resid√™ncia': 'Outro',
        'Acordo CPLP': 'Outro',
        'Outros Motivos': 'Outro'
    }).fillna('Outro')
    print(f"  ‚úì MotivoConcessao: {len(motivo_dim)} linhas")
    
    return {
        'AnoRelatorio': ano_dim,
        'TipoRelatorio': tipo_dim,
        'Sexo': sexo_dim,
        'Nacionalidade': nacionalidade_base,
        'NacionalidadeAIMA': nacionalidade_aima_dim,
        'Despacho': despacho_dim,
        'MotivoConcessao': motivo_dim
    }

# ========== SE√á√ÉO 6: CONSOLIDA√á√ÉO DE FATOS ==========

def consolidar_fatos(todos_dados):
    """
    Consolida todas tabelas fato de todos os anos
    """
    print(f"\n{'='*60}")
    print("üìä CONSOLIDANDO TABELAS FATO")
    print(f"{'='*60}\n")
    
    fatos = {}
    
    # Consolidar cada tipo de fato
    tipos_fato = [
        ('concessoes_nac_sexo', 'ConcessoesPorNacionalidadeSexo'),
        ('pop_est_nac_sexo', 'PopulacaoEstrangeiraPorNacionalidadeSexo'),
        ('concessoes_despacho', 'ConcessoesPorDespacho'),
        ('dist_etaria_conc', 'DistribuicaoEtariaConcessoes'),
        ('concessoes_motivo', 'ConcessoesPorMotivoNacionalidade'),
        ('pop_res_etaria', 'PopulacaoResidenteEtaria')
    ]
    
    for chave, nome in tipos_fato:
        dfs = [ano_data.get(chave, pd.DataFrame()) for ano_data in todos_dados.values()]
        dfs = [df for df in dfs if not df.empty]
        if dfs:
            fatos[nome] = pd.concat(dfs, ignore_index=True)
            print(f"  ‚úì {nome}: {len(fatos[nome])} linhas")
    
    return fatos

# ========== SE√á√ÉO 7: EXECU√á√ÉO PRINCIPAL ==========

def main():
    """
    Pipeline ETL completo
    """
    import os
    
    print("\n" + "="*60)
    print("üöÄ ETL AIMA/SEF - IN√çCIO")
    print("="*60)
    
    # Processar todos os anos
    todos_dados = {}
    for ano in sorted(ANOS_CONFIG.keys()):
        todos_dados[ano] = processar_ano(ano)
    
    # Construir dimens√µes
    dimensoes = construir_dimensoes(todos_dados)
    
    # Consolidar fatos
    fatos = consolidar_fatos(todos_dados)
    
    # Criar pasta data no Colab
    output_dir = '/content/data'
    os.makedirs(output_dir, exist_ok=True)
    
    # Salvar todos os CSVs na pasta
    print(f"\n{'='*60}")
    print(f"üíæ SALVANDO ARQUIVOS CSV EM {output_dir}")
    print(f"{'='*60}\n")
    
    todas_tabelas = {**dimensoes, **fatos}
    arquivos_salvos = 0
    
    for nome, df in todas_tabelas.items():
        if not df.empty:
            filepath = f"{output_dir}/{nome}.csv"
            df.to_csv(filepath, index=False)
            arquivos_salvos += 1
            print(f"  ‚úì {nome}.csv ({len(df)} linhas, {len(df.columns)} colunas)")
    
    print(f"\n{'='*60}")
    print("üéâ ETL CONCLU√çDO COM SUCESSO!")
    print(f"{'='*60}")
    print(f"\nüìä Resumo:")
    print(f"  ‚Ä¢ {len(dimensoes)} Dimens√µes criadas")
    print(f"  ‚Ä¢ {len(fatos)} Tabelas Fato criadas")
    print(f"  ‚Ä¢ {arquivos_salvos} arquivos CSV salvos em {output_dir}/")
    print(f"\nüìÇ Arquivos dispon√≠veis:")
    for arquivo in sorted(os.listdir(output_dir)):
        tamanho = os.path.getsize(f"{output_dir}/{arquivo}") / 1024
        print(f"   ‚Ä¢ {arquivo} ({tamanho:.1f} KB)")
    print()

# ========== EXECUTAR ETL ==========
if __name__ == "__main__":
    main()
