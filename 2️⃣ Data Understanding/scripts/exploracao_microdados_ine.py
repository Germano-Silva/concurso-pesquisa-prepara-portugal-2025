#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Explora√ß√£o de Microdados do INE - Censos 2021
==============================================

Projeto: Concurso de Pesquisa Prepara Portugal 2025
Tema: O Perfil S√≥cio-profissional do Imigrante em Portugal
Foco: Rela√ß√£o entre N√≠vel Educacional e Inser√ß√£o no Mercado de Trabalho
Data: Novembro 2025

Este script realiza uma an√°lise explorat√≥ria completa dos dados do INE dos Censos 2021,
focando em tr√™s vari√°veis-chave:
- Nacionalidade (popula√ß√£o estrangeira)
- Habilita√ß√µes Liter√°rias (n√≠vel educacional)
- Setor de Atividade Econ√≥mica (inser√ß√£o laboral)

Datasets Analisados:
1. Q2.1.csv - Habilita√ß√µes Liter√°rias por Nacionalidade
2. Q3.3.csv - Setor de Atividade por Nacionalidade
3. Q1.1.csv - Demografia por Nacionalidade (2011-2021)
4. Q13.csv - Educa√ß√£o Geral (compara√ß√£o nacional)
5. Q21.csv - Setores de Atividade Geral (compara√ß√£o nacional)

Autor: Sistema de An√°lise de Dados
"""

# =============================================================================
# IMPORTS E CONFIGURA√á√ïES INICIAIS
# =============================================================================

# Bibliotecas essenciais para manipula√ß√£o e an√°lise de dados
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from pathlib import Path
import sys
import os
from typing import Optional, Dict, List, Tuple, Union

# Configura√ß√µes gerais do pandas para melhor visualiza√ß√£o dos dados
pd.set_option('display.max_columns', None)  # Mostrar todas as colunas
pd.set_option('display.width', None)        # Largura ilimitada
pd.set_option('display.max_colwidth', 50)   # M√°ximo 50 caracteres por coluna

# Configura√ß√µes para matplotlib e seaborn
plt.style.use('default')                    # Estilo padr√£o do matplotlib
sns.set_palette("husl")                     # Paleta de cores harmoniosa
warnings.filterwarnings('ignore')           # Suprimir avisos desnecess√°rios

# Configura√ß√µes espec√≠ficas para gr√°ficos
plt.rcParams['figure.figsize'] = (12, 8)    # Tamanho padr√£o das figuras
plt.rcParams['font.size'] = 10               # Tamanho da fonte
plt.rcParams['font.family'] = 'sans-serif'  # Fam√≠lia da fonte

# =============================================================================
# CONFIGURA√á√ÉO DE CAMINHOS E CONSTANTES
# =============================================================================

class ConfiguracaoCaminhos:
    """
    Classe para gerenciar todos os caminhos dos arquivos de dados.
    
    Esta classe centraliza a configura√ß√£o de caminhos para facilitar
    a manuten√ß√£o e portabilidade do c√≥digo.
    """
    
    def __init__(self, diretorio_base: str = "data/raw/ine"):
        """
        Inicializa as configura√ß√µes de caminhos.
        
        Args:
            diretorio_base (str): Diret√≥rio base onde est√£o os dados do INE
        """
        self.BASE_PATH = Path(diretorio_base)
        self.CENSOS_CSV_PATH = self.BASE_PATH / "Censos2021_csv"
        self.POPULACAO_ESTRANGEIRA_PATH = self.BASE_PATH / "Censos2021_Popula√ß√£o estrangeira"
        
        # Dicion√°rio com todos os datasets principais utilizados na an√°lise
        self.DATASETS = {
            'educacao_nacionalidade': self.POPULACAO_ESTRANGEIRA_PATH / "Q2.1.csv",
            'setores_nacionalidade': self.POPULACAO_ESTRANGEIRA_PATH / "Q3.3.csv", 
            'demografia_nacionalidade': self.POPULACAO_ESTRANGEIRA_PATH / "Q1.1.csv",
            'educacao_geral': self.CENSOS_CSV_PATH / "Q13.csv",
            'setores_geral': self.CENSOS_CSV_PATH / "Q21.csv"
        }
    
    def verificar_arquivos_existentes(self) -> Dict[str, bool]:
        """
        Verifica se todos os arquivos necess√°rios existem.
        
        Returns:
            Dict[str, bool]: Dicion√°rio indicando quais arquivos existem
        """
        status = {}
        for nome, caminho in self.DATASETS.items():
            status[nome] = caminho.exists()
        return status

# =============================================================================
# FUN√á√ïES UTILIT√ÅRIAS PARA AN√ÅLISE DE DADOS
# =============================================================================

def carregar_e_analisar_dataset(caminho_arquivo: Path, 
                               nome_dataset: str, 
                               encoding: str = 'utf-8') -> Optional[pd.DataFrame]:
    """
    Carrega um dataset CSV e retorna an√°lise estrutural completa.
    
    Esta fun√ß√£o tenta carregar um arquivo CSV com diferentes encodings
    e fornece informa√ß√µes detalhadas sobre a estrutura de dados.
    
    Args:
        caminho_arquivo (Path): Caminho para o arquivo CSV
        nome_dataset (str): Nome descritivo do dataset para logging
        encoding (str): Codifica√ß√£o do arquivo (padr√£o: utf-8)
    
    Returns:
        Optional[pd.DataFrame]: DataFrame carregado ou None se houver erro
    """
    try:
        # Primeira tentativa de carregamento com encoding padr√£o
        df = pd.read_csv(caminho_arquivo, encoding=encoding)
        
        print(f"\n{'='*60}")
        print(f"DATASET: {nome_dataset.upper()}")
        print(f"Arquivo: {caminho_arquivo.name}")
        print(f"{'='*60}")
        
        return df
        
    except UnicodeDecodeError:
        # Se falhar com UTF-8, tenta com ISO-8859-1 (comum em dados portugueses)
        print(f"AVISO: Erro de encoding UTF-8, tentando ISO-8859-1...")
        try:
            df = pd.read_csv(caminho_arquivo, encoding='iso-8859-1')
            print(f"SUCESSO: Carregado com sucesso usando ISO-8859-1")
            return df
        except Exception as e:
            print(f"ERRO: Erro ao carregar {caminho_arquivo}: {e}")
            return None
            
    except FileNotFoundError:
        print(f"ERRO: Arquivo n√£o encontrado: {caminho_arquivo}")
        return None
        
    except Exception as e:
        print(f"ERRO: Erro inesperado ao carregar {caminho_arquivo}: {e}")
        return None


def analisar_dados_ausentes(df: pd.DataFrame, nome_dataset: str) -> pd.DataFrame:
    """
    Analisa dados ausentes no dataset e retorna estat√≠sticas detalhadas.
    
    Esta fun√ß√£o √© crucial para avaliar a qualidade dos dados, identificando
    colunas com valores faltantes e calculando percentuais de completude.
    
    Args:
        df (pd.DataFrame): DataFrame para an√°lise
        nome_dataset (str): Nome do dataset para contextualiza√ß√£o
    
    Returns:
        pd.DataFrame: DataFrame com estat√≠sticas de missing data
    """
    print(f"\nAN√ÅLISE DE DADOS AUSENTES - {nome_dataset}")
    print("-" * 50)
    
    # Calcula contagem e percentual de valores ausentes por coluna
    valores_ausentes = df.isnull().sum()
    percentual_ausente = (valores_ausentes / len(df)) * 100
    
    # Cria DataFrame com estat√≠sticas organizadas
    dados_ausentes_df = pd.DataFrame({
        'Coluna': df.columns,
        'Valores_Ausentes': valores_ausentes.values,
        'Percentual_Ausente': percentual_ausente.values
    })
    
    # Ordena por percentual de dados ausentes (do maior para o menor)
    dados_ausentes_df = dados_ausentes_df[
        dados_ausentes_df['Valores_Ausentes'] > 0
    ].sort_values('Percentual_Ausente', ascending=False)
    
    # Apresenta resultados de forma clara
    if len(dados_ausentes_df) == 0:
        print("RESULTADO: Nenhum valor ausente encontrado!")
    else:
        print(f"AVISO: Encontrados valores ausentes em {len(dados_ausentes_df)} colunas:")
        print(dados_ausentes_df.to_string(index=False))
    
    return dados_ausentes_df


def criar_estatisticas_resumo(df: pd.DataFrame, 
                             colunas_categoricas: List[str], 
                             colunas_numericas: List[str] = None) -> Dict:
    """
    Cria estat√≠sticas resumo abrangentes para colunas categ√≥ricas e num√©ricas.
    
    Esta fun√ß√£o gera um dicion√°rio com estat√≠sticas descritivas essenciais
    para compreender a distribui√ß√£o e caracter√≠sticas dos dados.
    
    Args:
        df (pd.DataFrame): DataFrame para an√°lise
        colunas_categoricas (List[str]): Lista de colunas categ√≥ricas
        colunas_numericas (List[str], optional): Lista de colunas num√©ricas
    
    Returns:
        Dict: Dicion√°rio com estat√≠sticas organizadas por tipo de coluna
    """
    if colunas_numericas is None:
        colunas_numericas = []
    
    estatisticas = {}
    
    # An√°lise de colunas categ√≥ricas
    for coluna in colunas_categoricas:
        if coluna in df.columns:
            # Estat√≠sticas b√°sicas para vari√°veis categ√≥ricas
            valores_unicos = df[coluna].nunique()
            
            # Valor mais frequente (moda)
            moda = df[coluna].mode()
            valor_mais_frequente = moda.iloc[0] if len(moda) > 0 else None
            
            # Frequ√™ncia do valor mais comum
            frequencia_maxima = df[coluna].value_counts().iloc[0] if len(df[coluna]) > 0 else 0
            
            # Top 5 valores mais frequentes
            top_5_valores = df[coluna].value_counts().head().to_dict()
            
            estatisticas[coluna] = {
                'valores_unicos': valores_unicos,
                'valor_mais_frequente': valor_mais_frequente,
                'frequencia_maxima': frequencia_maxima,
                'top_5_valores': top_5_valores
            }
    
    # An√°lise de colunas num√©ricas
    for coluna in colunas_numericas:
        if coluna in df.columns:
            # Usa a fun√ß√£o describe() do pandas para estat√≠sticas descritivas completas
            estatisticas[coluna] = df[coluna].describe().to_dict()
    
    return estatisticas


def extrair_nacionalidades(df: pd.DataFrame, nome_dataset: str) -> Optional[List[str]]:
    """
    Extrai e analisa as nacionalidades presentes em um dataset.
    
    Esta fun√ß√£o identifica e filtra as nacionalidades v√°lidas,
    excluindo linhas de cabe√ßalho, totais e outros valores n√£o relevantes.
    
    Args:
        df (pd.DataFrame): DataFrame para an√°lise
        nome_dataset (str): Nome do dataset para contextualiza√ß√£o
    
    Returns:
        Optional[List[str]]: Lista de nacionalidades identificadas ou None se erro
    """
    if df is None:
        print(f"‚ùå Dataset {nome_dataset} n√£o dispon√≠vel")
        return None
    
    # Assume que as nacionalidades est√£o na primeira coluna
    primeira_coluna = df.iloc[:, 0]
    
    # Extrai todas as entradas n√£o nulas
    nacionalidades = primeira_coluna[primeira_coluna.notna()].tolist()
    
    # Define filtros para excluir valores que n√£o s√£o nacionalidades
    filtros_exclusao = [
        'total', 'popula√ß√£o', 'quadro', 'nacionalidade', 
        'fonte', 'ine', 'portugal', 'estrangeira', 'residente'
    ]
    
    # Filtra nacionalidades v√°lidas
    nacionalidades_filtradas = [
        str(nac) for nac in nacionalidades 
        if not any(filtro in str(nac).lower() for filtro in filtros_exclusao)
        and len(str(nac)) > 2  # Exclui c√≥digos muito curtos
        and str(nac).strip() != ''  # Exclui strings vazias
    ]
    
    # Apresenta resultados da an√°lise
    print(f"\nüìä AN√ÅLISE DE NACIONALIDADES - {nome_dataset}:")
    print(f"   ‚Ä¢ Total de entradas: {len(nacionalidades)}")
    print(f"   ‚Ä¢ Nacionalidades v√°lidas identificadas: {len(nacionalidades_filtradas)}")
    
    if len(nacionalidades_filtradas) > 0:
        print(f"   ‚Ä¢ Top 10 nacionalidades:")
        for i, nacionalidade in enumerate(nacionalidades_filtradas[:10], 1):
            print(f"     {i:2d}. {nacionalidade}")
    
    return nacionalidades_filtradas


def analisar_setores_atividade(df: pd.DataFrame) -> Dict[str, str]:
    """
    Analisa e mapeia os setores de atividade econ√≥mica presentes nos dados.
    
    Esta fun√ß√£o identifica os setores CAE (Classifica√ß√£o das Atividades Econ√≥micas)
    e fornece descri√ß√µes completas para facilitar a interpreta√ß√£o.
    
    Args:
        df (pd.DataFrame): DataFrame com dados de setores de atividade
    
    Returns:
        Dict[str, str]: Mapeamento c√≥digo CAE -> descri√ß√£o do setor
    """
    print("üè≠ AN√ÅLISE DOS SETORES DE ATIVIDADE ECON√ìMICA")
    print("=" * 50)
    
    if df is None:
        print("‚ùå Dataset de setores n√£o dispon√≠vel")
        return {}
    
    # Analisa estrutura das colunas
    colunas = list(df.columns)
    print(f"üìã Total de colunas identificadas: {len(colunas)}")
    
    # Identifica colunas de setores (geralmente ap√≥s as primeiras 2 colunas de identifica√ß√£o)
    colunas_setoriais = colunas[2:] if len(colunas) > 2 else []
    
    if len(colunas_setoriais) > 0:
        print(f"üéØ SETORES CAE IDENTIFICADOS ({len(colunas_setoriais)} setores):")
        
        # Mapeamento completo dos setores CAE conhecidos
        setores_cae = {
            'A': 'Agricultura, produ√ß√£o animal, ca√ßa, floresta e pesca',
            'B': 'Ind√∫strias extractivas', 
            'C': 'Ind√∫strias transformadoras',
            'D': 'Electricidade, g√°s, vapor, √°gua quente e fria e ar frio',
            'E': 'Capta√ß√£o, tratamento e distribui√ß√£o de √°gua; saneamento, gest√£o de res√≠duos',
            'F': 'Constru√ß√£o',
            'G': 'Com√©rcio por grosso e a retalho; repara√ß√£o de ve√≠culos autom√≥veis',
            'H': 'Transportes e armazenagem',
            'I': 'Alojamento, restaura√ß√£o e similares',
            'J': 'Actividades de informa√ß√£o e de comunica√ß√£o',
            'K': 'Actividades financeiras e de seguros',
            'L': 'Actividades imobili√°rias',
            'M': 'Actividades de consultoria, cient√≠ficas, t√©cnicas e similares',
            'N': 'Actividades administrativas e dos servi√ßos de apoio',
            'O': 'Administra√ß√£o P√∫blica e Defesa; Seguran√ßa Social Obrigat√≥ria',
            'P': 'Educa√ß√£o',
            'Q': 'Actividades de sa√∫de humana e apoio social',
            'R': 'Actividades art√≠sticas, de espect√°culos, desportivas e recreativas',
            'S': 'Outras actividades de servi√ßos',
            'T': 'Atividades das fam√≠lias empregadoras de pessoal dom√©stico',
            'U': 'Actividades dos organismos internacionais'
        }
        
        # Apresenta mapeamento dos setores encontrados
        for i, coluna_setor in enumerate(colunas_setoriais, 1):
            letra_cae = chr(64 + i)  # Converte para A, B, C, etc.
            if letra_cae in setores_cae:
                print(f"   {letra_cae}. {setores_cae[letra_cae]}")
            else:
                print(f"   {letra_cae}. {coluna_setor}")
        
        return setores_cae
    
    return {}

# =============================================================================
# CLASSE PRINCIPAL PARA AN√ÅLISE DOS MICRODADOS
# =============================================================================

class AnalisadorMicrodadosINE:
    """
    Classe principal para an√°lise dos microdados do INE dos Censos 2021.
    
    Esta classe encapsula todos os m√©todos necess√°rios para carregar,
    processar e analisar os dados do INE de forma organizada e sistem√°tica.
    """
    
    def __init__(self, diretorio_dados: str = "data/raw/ine"):
        """
        Inicializa o analisador com configura√ß√µes padr√£o.
        
        Args:
            diretorio_dados (str): Diret√≥rio base dos dados do INE
        """
        self.config = ConfiguracaoCaminhos(diretorio_dados)
        self.datasets: Dict[str, pd.DataFrame] = {}
        self.nacionalidades: Dict[str, List[str]] = {}
        self.estatisticas: Dict[str, Dict] = {}
        
        print("üöÄ Analisador de Microdados do INE inicializado")
        print(f"üìÅ Diret√≥rio base: {self.config.BASE_PATH}")
    
    def verificar_disponibilidade_dados(self) -> None:
        """
        Verifica a disponibilidade de todos os arquivos de dados necess√°rios.
        """
        print("\nüîç VERIFICA√á√ÉO DE DISPONIBILIDADE DOS DADOS")
        print("=" * 50)
        
        status_arquivos = self.config.verificar_arquivos_existentes()
        
        for nome_dataset, existe in status_arquivos.items():
            status_emoji = "‚úÖ" if existe else "‚ùå"
            caminho_arquivo = self.config.DATASETS[nome_dataset]
            print(f"{status_emoji} {nome_dataset}: {caminho_arquivo.name}")
        
        arquivos_disponiveis = sum(status_arquivos.values())
        total_arquivos = len(status_arquivos)
        
        print(f"\nüìä Resumo: {arquivos_disponiveis}/{total_arquivos} arquivos dispon√≠veis")
        
        if arquivos_disponiveis == 0:
            print("‚ö†Ô∏è  AVISO: Nenhum arquivo de dados encontrado!")
            print("   Verifique se os dados est√£o no diret√≥rio correto.")
    
    def carregar_todos_datasets(self) -> None:
        """
        Carrega todos os datasets dispon√≠veis e realiza an√°lise estrutural b√°sica.
        """
        print("\nüì• CARREGAMENTO DE TODOS OS DATASETS")
        print("=" * 50)
        
        # Lista de datasets com nomes descritivos para melhor compreens√£o
        datasets_info = [
            ('educacao_nacionalidade', 'Habilita√ß√µes Liter√°rias por Nacionalidade'),
            ('setores_nacionalidade', 'Setores de Atividade por Nacionalidade'),
            ('demografia_nacionalidade', 'Demografia por Nacionalidade (2011-2021)'),
            ('educacao_geral', 'Educa√ß√£o Geral (compara√ß√£o nacional)'),
            ('setores_geral', 'Setores de Atividade Geral (compara√ß√£o nacional)')
        ]
        
        for nome_interno, nome_descritivo in datasets_info:
            if nome_interno in self.config.DATASETS:
                caminho = self.config.DATASETS[nome_interno]
                
                if caminho.exists():
                    # Carrega o dataset usando a fun√ß√£o utilit√°ria
                    df = carregar_e_analisar_dataset(caminho, nome_descritivo)
                    
                    if df is not None:
                        # Armazena o dataset para uso posterior
                        self.datasets[nome_interno] = df
                        
                        # Realiza an√°lise estrutural b√°sica
                        self._analisar_estrutura_basica(df, nome_descritivo)
                    else:
                        print(f"‚ùå Falha ao carregar: {nome_descritivo}")
                else:
                    print(f"‚ùå Arquivo n√£o encontrado: {nome_descritivo}")
    
    def _analisar_estrutura_basica(self, df: pd.DataFrame, nome_dataset: str) -> None:
        """
        Realiza an√°lise estrutural b√°sica de um dataset.
        
        Args:
            df (pd.DataFrame): DataFrame para an√°lise
            nome_dataset (str): Nome descritivo do dataset
        """
        print(f"üìê Dimens√µes: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas")
        print(f"üíæ Tamanho em mem√≥ria: {df.memory_usage(deep=True).sum() / 1024:.1f} KB")
        
        # Apresenta informa√ß√µes sobre tipos de dados
        print(f"üìä Tipos de dados:")
        tipos_dados = df.dtypes.value_counts()
        for tipo, contagem in tipos_dados.items():
            print(f"   ‚Ä¢ {tipo}: {contagem} colunas")
        
        # An√°lise de dados ausentes
        analisar_dados_ausentes(df, nome_dataset)
    
    def analisar_nacionalidades(self) -> None:
        """
        Analisa nacionalidades em todos os datasets carregados.
        """
        print("\nüåç AN√ÅLISE CONSOLIDADA DAS NACIONALIDADES")
        print("=" * 50)
        
        # Datasets que cont√©m informa√ß√µes sobre nacionalidades
        datasets_nacionalidades = [
            ('educacao_nacionalidade', 'Habilita√ß√µes Liter√°rias'),
            ('setores_nacionalidade', 'Setores de Atividade'),
            ('demografia_nacionalidade', 'Demografia')
        ]
        
        todas_nacionalidades = set()
        
        # Extrai nacionalidades de cada dataset
        for nome_dataset, nome_descritivo in datasets_nacionalidades:
            if nome_dataset in self.datasets:
                nacionalidades = extrair_nacionalidades(
                    self.datasets[nome_dataset], 
                    nome_descritivo
                )
                
                if nacionalidades:
                    self.nacionalidades[nome_dataset] = nacionalidades
                    todas_nacionalidades.update(nacionalidades)
        
        # Apresenta consolida√ß√£o geral
        print(f"\nüéØ CONSOLIDA√á√ÉO GERAL:")
        print(f"   ‚Ä¢ Total de nacionalidades √∫nicas: {len(todas_nacionalidades)}")
        
        # Encontra nacionalidades presentes em m√∫ltiplos datasets
        if 'educacao_nacionalidade' in self.nacionalidades and 'setores_nacionalidade' in self.nacionalidades:
            nacionalidades_comuns = (
                set(self.nacionalidades['educacao_nacionalidade']) & 
                set(self.nacionalidades['setores_nacionalidade'])
            )
            
            print(f"   ‚Ä¢ Nacionalidades em m√∫ltiplos datasets: {len(nacionalidades_comuns)}")
            
            if len(nacionalidades_comuns) > 0:
                print(f"\nüìã Nacionalidades mais representativas:")
                for i, nacionalidade in enumerate(sorted(list(nacionalidades_comuns))[:12], 1):
                    print(f"     {i:2d}. {nacionalidade}")
    
    def analisar_contexto_temporal_geografico(self) -> None:
        """
        Analisa o contexto temporal e geogr√°fico dos dados dos Censos 2021.
        """
        print("\nüìÖ AN√ÅLISE TEMPORAL E GEOGR√ÅFICA DOS DADOS")
        print("=" * 60)
        
        # Informa√ß√µes contextuais dos Censos 2021
        info_censos = {
            'Data de Refer√™ncia': '19 de abril de 2021',
            'Per√≠odo de Coleta': 'Abril-Julho 2021', 
            'Cobertura Geogr√°fica': 'Portugal (Continental + Regi√µes Aut√≥nomas)',
            'Metodologia': 'Recenseamento por via eletr√¥nica e presencial',
            'Compara√ß√£o Temporal': 'Censos 2011 (algumas vari√°veis)',
            'N√≠vel de Desagrega√ß√£o': 'Nacional, NUTS I/II/III, Municipal, Freguesia'
        }
        
        print("üóìÔ∏è  CONTEXTO TEMPORAL:")
        for chave, valor in info_censos.items():
            print(f"   ‚Ä¢ {chave}: {valor}")
        
        # An√°lise dos datasets carregados
        print(f"\nüìä CARACTER√çSTICAS DOS DATASETS CARREGADOS:")
        print("-" * 50)
        
        for nome_interno, df in self.datasets.items():
            nome_legivel = nome_interno.replace('_', ' ').title()
            print(f"\nüìã {nome_legivel}:")
            
            # Verifica colunas temporais
            colunas_temporais = [
                col for col in df.columns 
                if any(termo in str(col).lower() for termo in ['2021', '2011', 'ano', 'data'])
            ]
            
            if colunas_temporais:
                print(f"   ‚è∞ Colunas temporais: {colunas_temporais}")
            else:
                print(f"   üìÖ Per√≠odo: Censos 2021 (impl√≠cito)")
            
            # Verifica granularidade geogr√°fica
            colunas_geograficas = [
                col for col in df.columns 
                if any(termo in str(col).lower() for termo in ['nuts', 'distrito', 'concelho', 'freguesia', 'regi√£o'])
            ]
            
            if colunas_geograficas:
                print(f"   üó∫Ô∏è  Colunas geogr√°ficas: {colunas_geograficas}")
            else:
                print(f"   üó∫Ô∏è  N√≠vel geogr√°fico: Nacional (agregado)")
            
            print(f"   üìä Dimens√£o: {df.shape[0]:,} observa√ß√µes √ó {df.shape[1]} vari√°veis")
        
        # Adequa√ß√£o para perguntas de pesquisa
        print(f"\nüéØ ADEQUA√á√ÉO PARA AS PERGUNTAS DE PESQUISA:")
        adequacao_perguntas = {
            "1. Evolu√ß√£o educacional (5-10 anos)": "‚úÖ Adequado (2011 vs 2021 = 10 anos)",
            "2. Distribui√ß√£o setorial atual": "‚úÖ Adequado (dados 2021 detalhados)", 
            "3. Perfil educacional por setor": "‚úÖ Adequado (cruzamento poss√≠vel)",
            "4. Diferen√ßas por nacionalidade": "‚úÖ Adequado (15+ nacionalidades)"
        }
        
        for pergunta, status in adequacao_perguntas.items():
            print(f"   {status} {pergunta}")
    
    def gerar_relatorio_completo(self) -> None:
        """
        Gera um relat√≥rio completo com todas as an√°lises realizadas.
        """
        print("\nüìã RELAT√ìRIO COMPLETO DA AN√ÅLISE")
        print("=" * 60)
        
        # Verifica disponibilidade dos dados
        self.verificar_disponibilidade_dados()
        
        # Carrega todos os datasets
        self.carregar_todos_datasets()
        
        # Realiza an√°lises espec√≠ficas
        self.analisar_nacionalidades()
        self.analisar_contexto_temporal_geografico()
        
        # An√°lise de setores de atividade (se dados dispon√≠veis)
        if 'setores_nacionalidade' in self.datasets:
            analisar_setores_atividade(self.datasets['setores_nacionalidade'])
        
        # Sum√°rio final
        print(f"\n‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        print(f"üìä Datasets processados: {len(self.datasets)}")
        print(f"üåç Categorias de nacionalidades identificadas: {len(self.nacionalidades)}")

# =============================================================================
# FUN√á√ÉO PRINCIPAL DE EXECU√á√ÉO
# =============================================================================

def executar_analise_completa(diretorio_dados: str = "data/raw/ine") -> None:
    """
    Fun√ß√£o principal que executa toda a an√°lise dos microdados do INE.
    
    Esta fun√ß√£o orquestra todo o processo de an√°lise de dados, desde o
    carregamento at√© a gera√ß√£o do relat√≥rio final.
    
    Args:
        diretorio_dados (str): Diret√≥rio onde est√£o localizados os dados do INE
    """
    print("üéØ INICIANDO AN√ÅLISE EXPLORAT√ìRIA DOS MICRODADOS DO INE")
    print("=" * 70)
    print("Projeto: Concurso de Pesquisa Prepara Portugal 2025")
    print("Foco: O Perfil S√≥cio-profissional do Imigrante em Portugal")
    print("=" * 70)
    
    try:
        # Instancia o analisador principal
        analisador = AnalisadorMicrodadosINE(diretorio_dados)
        
        # Executa an√°lise completa
        analisador.gerar_relatorio_completo()
        
        print(f"\nüéâ AN√ÅLISE FINALIZADA COM SUCESSO!")
        print(f"üìã Para mais detalhes, consulte os outputs acima.")
        
    except Exception as e:
        print(f"‚ùå ERRO DURANTE A AN√ÅLISE: {str(e)}")
        print("   Verifique se os arquivos de dados est√£o no diret√≥rio correto.")
        print("   Certifique-se de que os dados est√£o no formato esperado.")
        raise


def mostrar_ajuda() -> None:
    """
    Mostra informa√ß√µes de ajuda sobre como usar este script.
    """
    ajuda = """
üîß COMO USAR ESTE SCRIPT

Este script analisa os microdados do INE dos Censos 2021, focando no perfil
s√≥cio-profissional da popula√ß√£o imigrante em Portugal.

üìÇ ESTRUTURA DE DADOS ESPERADA:
data/raw/ine/
‚îú‚îÄ‚îÄ Censos2021_csv/
‚îÇ   ‚îú‚îÄ‚îÄ Q13.csv
‚îÇ   ‚îî‚îÄ‚îÄ Q21.csv
‚îî‚îÄ‚îÄ Censos2021_Popula√ß√£o estrangeira/
    ‚îú‚îÄ‚îÄ Q1.1.csv
    ‚îú‚îÄ‚îÄ Q2.1.csv
    ‚îî‚îÄ‚îÄ Q3.3.csv

üöÄ FORMAS DE EXECU√á√ÉO:

1. Execu√ß√£o b√°sica (dados no diret√≥rio padr√£o):
   python exploracao_microdados_ine.py

2. Especificando diret√≥rio customizado:
   python exploracao_microdados_ine.py --diretorio /caminho/para/dados

3. Mostrando esta ajuda:
   python exploracao_microdados_ine.py --help

üìä O QUE O SCRIPT FAZ:
- Verifica disponibilidade dos arquivos de dados
- Carrega e analisa estrutura dos datasets
- Identifica nacionalidades presentes nos dados  
- Analisa setores de atividade econ√≥mica
- Examina contexto temporal e geogr√°fico
- Detecta dados ausentes
- Gera relat√≥rio completo de an√°lise

üí° DICAS:
- Certifique-se de que os arquivos CSV est√£o em encoding UTF-8 ou ISO-8859-1
- O script tenta automaticamente diferentes encodings se houver problemas
- Todos os outputs s√£o apresentados em portugu√™s
"""
    print(ajuda)


def analisar_argumentos_linha_comando() -> str:
    """
    Analisa argumentos da linha de comando.
    
    Returns:
        str: Diret√≥rio de dados especificado pelo usu√°rio ou padr√£o
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="An√°lise de Microdados do INE - Censos 2021",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python exploracao_microdados_ine.py
  python exploracao_microdados_ine.py --diretorio /caminho/para/dados
  python exploracao_microdados_ine.py --help
        """
    )
    
    parser.add_argument(
        '--diretorio', '-d',
        default="data/raw/ine",
        help='Diret√≥rio base onde est√£o os dados do INE (padr√£o: data/raw/ine)'
    )
    
    parser.add_argument(
        '--ajuda', '--help',
        action='store_true',
        help='Mostra informa√ß√µes detalhadas de ajuda'
    )
    
    args = parser.parse_args()
    
    if args.ajuda:
        mostrar_ajuda()
        sys.exit(0)
    
    return args.diretorio


# =============================================================================
# EXECU√á√ÉO PRINCIPAL DO SCRIPT
# =============================================================================

if __name__ == "__main__":
    """
    Ponto de entrada principal do script.
    
    Esta se√ß√£o √© executada apenas quando o script √© rodado diretamente,
    n√£o quando √© importado como m√≥dulo em outros scripts.
    """
    
    # Configura encoding para output correto em portugu√™s
    if sys.stdout.encoding != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')
    
    try:
        # Analisa argumentos da linha de comando
        diretorio_dados = analisar_argumentos_linha_comando()
        
        # Executa an√°lise completa
        executar_analise_completa(diretorio_dados)
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Execu√ß√£o interrompida pelo usu√°rio.")
        sys.exit(1)
        
    except Exception as e:
        print(f"\n‚ùå ERRO FATAL: {str(e)}")
        print("   Consulte a documenta√ß√£o ou execute com --ajuda para mais informa√ß√µes.")
        sys.exit(1)

# =============================================================================
# FIM DO SCRIPT
# =============================================================================
